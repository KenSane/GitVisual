{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\janry\\\\Music\\\\VisualQuery\\\\frontend\\\\src\\\\component\\\\HeadPoseAndEmotionDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useRef, useEffect, useState } from 'react';\nimport * as mp from '@mediapipe/face_mesh';\nimport * as cam from '@mediapipe/camera_utils';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst HeadPoseAndEmotionDetection = _ref => {\n  _s();\n  let {\n    setHeadPose,\n    setEmotion\n  } = _ref;\n  const videoRef = useRef(null);\n  const [isModelsLoaded, setIsModelsLoaded] = useState(false);\n  useEffect(() => {\n    const loadFaceApiModels = async () => {\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\n      setIsModelsLoaded(true);\n    };\n    const startVideoAndDetection = async () => {\n      const faceMesh = new mp.FaceMesh({\n        locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`\n      });\n      faceMesh.setOptions({\n        maxNumFaces: 1,\n        refineLandmarks: true,\n        minDetectionConfidence: 0.5,\n        minTrackingConfidence: 0.5\n      });\n      faceMesh.onResults(onResults);\n      let camera;\n      if (typeof videoRef.current !== 'undefined' && videoRef.current !== null) {\n        camera = new cam.Camera(videoRef.current, {\n          onFrame: async () => {\n            await faceMesh.send({\n              image: videoRef.current\n            });\n            if (isModelsLoaded) {\n              detectEmotion();\n            }\n          },\n          width: 640,\n          height: 480\n        });\n        camera.start();\n      }\n      function onResults(results) {\n        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {\n          const landmarks = results.multiFaceLandmarks[0];\n          const noseTip = landmarks[1];\n          const leftCheek = landmarks[33];\n          const rightCheek = landmarks[263];\n          const dx = rightCheek.x - leftCheek.x;\n          const dy = rightCheek.y - leftCheek.y;\n          const angleY = Math.atan2(dy, dx) * (180 / Math.PI);\n          const noseBottom = landmarks[2];\n          const chin = landmarks[152];\n          const dz = chin.y - noseBottom.y;\n          const angleX = Math.atan2(dz, dx) * (180 / Math.PI);\n          let pose = 'forward';\n          if (angleY < -10) {\n            pose = 'left';\n          } else if (angleX > 17) {\n            pose = 'up';\n          } else if (angleX < -1) {\n            pose = 'down';\n          }\n          setHeadPose(pose);\n        }\n      }\n      const detectEmotion = async () => {\n        if (videoRef.current) {\n          const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n          if (detections.length > 0) {\n            const emotions = detections[0].expressions;\n            const maxValue = Math.max(...Object.values(emotions));\n            const emotion = Object.keys(emotions).find(key => emotions[key] === maxValue);\n            setEmotion(emotion);\n          }\n        }\n      };\n    };\n    loadFaceApiModels().then(startVideoAndDetection);\n    return () => {\n      if (videoRef.current && videoRef.current.srcObject) {\n        videoRef.current.srcObject.getTracks().forEach(track => track.stop());\n      }\n    };\n  }, [setHeadPose, setEmotion, isModelsLoaded]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true,\n      muted: true,\n      width: \"640\",\n      height: \"480\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 103,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 102,\n    columnNumber: 5\n  }, this);\n};\n_s(HeadPoseAndEmotionDetection, \"QjZUUdAXu2FHCYadH3+phmEi27E=\");\n_c = HeadPoseAndEmotionDetection;\nexport default HeadPoseAndEmotionDetection;\nvar _c;\n$RefreshReg$(_c, \"HeadPoseAndEmotionDetection\");","map":{"version":3,"names":["React","useRef","useEffect","useState","mp","cam","faceapi","jsxDEV","_jsxDEV","HeadPoseAndEmotionDetection","_ref","_s","setHeadPose","setEmotion","videoRef","isModelsLoaded","setIsModelsLoaded","loadFaceApiModels","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","startVideoAndDetection","faceMesh","FaceMesh","locateFile","file","setOptions","maxNumFaces","refineLandmarks","minDetectionConfidence","minTrackingConfidence","onResults","camera","current","Camera","onFrame","send","image","detectEmotion","width","height","start","results","multiFaceLandmarks","length","landmarks","noseTip","leftCheek","rightCheek","dx","x","dy","y","angleY","Math","atan2","PI","noseBottom","chin","dz","angleX","pose","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","emotions","expressions","maxValue","max","Object","values","emotion","keys","find","key","then","srcObject","getTracks","forEach","track","stop","children","ref","autoPlay","muted","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/janry/Music/VisualQuery/frontend/src/component/HeadPoseAndEmotionDetection.js"],"sourcesContent":["import React, { useRef, useEffect, useState } from 'react';\r\nimport * as mp from '@mediapipe/face_mesh';\r\nimport * as cam from '@mediapipe/camera_utils';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst HeadPoseAndEmotionDetection = ({ setHeadPose, setEmotion }) => {\r\n  const videoRef = useRef(null);\r\n  const [isModelsLoaded, setIsModelsLoaded] = useState(false);\r\n\r\n  useEffect(() => {\r\n    const loadFaceApiModels = async () => {\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\r\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\r\n      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\r\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\r\n      setIsModelsLoaded(true);\r\n    };\r\n\r\n    const startVideoAndDetection = async () => {\r\n      const faceMesh = new mp.FaceMesh({\r\n        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,\r\n      });\r\n\r\n      faceMesh.setOptions({\r\n        maxNumFaces: 1,\r\n        refineLandmarks: true,\r\n        minDetectionConfidence: 0.5,\r\n        minTrackingConfidence: 0.5,\r\n      });\r\n\r\n      faceMesh.onResults(onResults);\r\n\r\n      let camera;\r\n      if (typeof videoRef.current !== 'undefined' && videoRef.current !== null) {\r\n        camera = new cam.Camera(videoRef.current, {\r\n          onFrame: async () => {\r\n            await faceMesh.send({ image: videoRef.current });\r\n            if (isModelsLoaded) {\r\n              detectEmotion();\r\n            }\r\n          },\r\n          width: 640,\r\n          height: 480,\r\n        });\r\n        camera.start();\r\n      }\r\n\r\n      function onResults(results) {\r\n        if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {\r\n          const landmarks = results.multiFaceLandmarks[0];\r\n\r\n          const noseTip = landmarks[1];\r\n          const leftCheek = landmarks[33];\r\n          const rightCheek = landmarks[263];\r\n\r\n          const dx = rightCheek.x - leftCheek.x;\r\n          const dy = rightCheek.y - leftCheek.y;\r\n          const angleY = Math.atan2(dy, dx) * (180 / Math.PI);\r\n\r\n          const noseBottom = landmarks[2];\r\n          const chin = landmarks[152];\r\n\r\n          const dz = chin.y - noseBottom.y;\r\n          const angleX = Math.atan2(dz, dx) * (180 / Math.PI);\r\n\r\n          let pose = 'forward';\r\n          if (angleY < -10) {\r\n            pose = 'left';\r\n          } else if (angleX > 17) {\r\n            pose = 'up';\r\n          } else if (angleX < -1) {\r\n            pose = 'down';\r\n          }\r\n\r\n          setHeadPose(pose);\r\n        }\r\n      }\r\n\r\n      const detectEmotion = async () => {\r\n        if (videoRef.current) {\r\n          const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\r\n          if (detections.length > 0) {\r\n            const emotions = detections[0].expressions;\r\n            const maxValue = Math.max(...Object.values(emotions));\r\n            const emotion = Object.keys(emotions).find(key => emotions[key] === maxValue);\r\n            setEmotion(emotion);\r\n          }\r\n        }\r\n      };\r\n    };\r\n\r\n    loadFaceApiModels().then(startVideoAndDetection);\r\n\r\n    return () => {\r\n      if (videoRef.current && videoRef.current.srcObject) {\r\n        videoRef.current.srcObject.getTracks().forEach(track => track.stop());\r\n      }\r\n    };\r\n  }, [setHeadPose, setEmotion, isModelsLoaded]);\r\n\r\n  return (\r\n    <div>\r\n      <video ref={videoRef} autoPlay muted width=\"640\" height=\"480\" />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default HeadPoseAndEmotionDetection;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,EAAEC,QAAQ,QAAQ,OAAO;AAC1D,OAAO,KAAKC,EAAE,MAAM,sBAAsB;AAC1C,OAAO,KAAKC,GAAG,MAAM,yBAAyB;AAC9C,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,2BAA2B,GAAGC,IAAA,IAAiC;EAAAC,EAAA;EAAA,IAAhC;IAAEC,WAAW;IAAEC;EAAW,CAAC,GAAAH,IAAA;EAC9D,MAAMI,QAAQ,GAAGb,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAM,CAACc,cAAc,EAAEC,iBAAiB,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC;EAE3DD,SAAS,CAAC,MAAM;IACd,MAAMe,iBAAiB,GAAG,MAAAA,CAAA,KAAY;MACpC,MAAMX,OAAO,CAACY,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;MAC1D,MAAMd,OAAO,CAACY,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC;MAC3D,MAAMd,OAAO,CAACY,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAAC,SAAS,CAAC;MAC5D,MAAMd,OAAO,CAACY,IAAI,CAACK,iBAAiB,CAACH,WAAW,CAAC,SAAS,CAAC;MAC3DJ,iBAAiB,CAAC,IAAI,CAAC;IACzB,CAAC;IAED,MAAMQ,sBAAsB,GAAG,MAAAA,CAAA,KAAY;MACzC,MAAMC,QAAQ,GAAG,IAAIrB,EAAE,CAACsB,QAAQ,CAAC;QAC/BC,UAAU,EAAGC,IAAI,IAAM,qDAAoDA,IAAK;MAClF,CAAC,CAAC;MAEFH,QAAQ,CAACI,UAAU,CAAC;QAClBC,WAAW,EAAE,CAAC;QACdC,eAAe,EAAE,IAAI;QACrBC,sBAAsB,EAAE,GAAG;QAC3BC,qBAAqB,EAAE;MACzB,CAAC,CAAC;MAEFR,QAAQ,CAACS,SAAS,CAACA,SAAS,CAAC;MAE7B,IAAIC,MAAM;MACV,IAAI,OAAOrB,QAAQ,CAACsB,OAAO,KAAK,WAAW,IAAItB,QAAQ,CAACsB,OAAO,KAAK,IAAI,EAAE;QACxED,MAAM,GAAG,IAAI9B,GAAG,CAACgC,MAAM,CAACvB,QAAQ,CAACsB,OAAO,EAAE;UACxCE,OAAO,EAAE,MAAAA,CAAA,KAAY;YACnB,MAAMb,QAAQ,CAACc,IAAI,CAAC;cAAEC,KAAK,EAAE1B,QAAQ,CAACsB;YAAQ,CAAC,CAAC;YAChD,IAAIrB,cAAc,EAAE;cAClB0B,aAAa,CAAC,CAAC;YACjB;UACF,CAAC;UACDC,KAAK,EAAE,GAAG;UACVC,MAAM,EAAE;QACV,CAAC,CAAC;QACFR,MAAM,CAACS,KAAK,CAAC,CAAC;MAChB;MAEA,SAASV,SAASA,CAACW,OAAO,EAAE;QAC1B,IAAIA,OAAO,CAACC,kBAAkB,IAAID,OAAO,CAACC,kBAAkB,CAACC,MAAM,GAAG,CAAC,EAAE;UACvE,MAAMC,SAAS,GAAGH,OAAO,CAACC,kBAAkB,CAAC,CAAC,CAAC;UAE/C,MAAMG,OAAO,GAAGD,SAAS,CAAC,CAAC,CAAC;UAC5B,MAAME,SAAS,GAAGF,SAAS,CAAC,EAAE,CAAC;UAC/B,MAAMG,UAAU,GAAGH,SAAS,CAAC,GAAG,CAAC;UAEjC,MAAMI,EAAE,GAAGD,UAAU,CAACE,CAAC,GAAGH,SAAS,CAACG,CAAC;UACrC,MAAMC,EAAE,GAAGH,UAAU,CAACI,CAAC,GAAGL,SAAS,CAACK,CAAC;UACrC,MAAMC,MAAM,GAAGC,IAAI,CAACC,KAAK,CAACJ,EAAE,EAAEF,EAAE,CAAC,IAAI,GAAG,GAAGK,IAAI,CAACE,EAAE,CAAC;UAEnD,MAAMC,UAAU,GAAGZ,SAAS,CAAC,CAAC,CAAC;UAC/B,MAAMa,IAAI,GAAGb,SAAS,CAAC,GAAG,CAAC;UAE3B,MAAMc,EAAE,GAAGD,IAAI,CAACN,CAAC,GAAGK,UAAU,CAACL,CAAC;UAChC,MAAMQ,MAAM,GAAGN,IAAI,CAACC,KAAK,CAACI,EAAE,EAAEV,EAAE,CAAC,IAAI,GAAG,GAAGK,IAAI,CAACE,EAAE,CAAC;UAEnD,IAAIK,IAAI,GAAG,SAAS;UACpB,IAAIR,MAAM,GAAG,CAAC,EAAE,EAAE;YAChBQ,IAAI,GAAG,MAAM;UACf,CAAC,MAAM,IAAID,MAAM,GAAG,EAAE,EAAE;YACtBC,IAAI,GAAG,IAAI;UACb,CAAC,MAAM,IAAID,MAAM,GAAG,CAAC,CAAC,EAAE;YACtBC,IAAI,GAAG,MAAM;UACf;UAEApD,WAAW,CAACoD,IAAI,CAAC;QACnB;MACF;MAEA,MAAMvB,aAAa,GAAG,MAAAA,CAAA,KAAY;QAChC,IAAI3B,QAAQ,CAACsB,OAAO,EAAE;UACpB,MAAM6B,UAAU,GAAG,MAAM3D,OAAO,CAAC4D,cAAc,CAACpD,QAAQ,CAACsB,OAAO,EAAE,IAAI9B,OAAO,CAAC6D,uBAAuB,CAAC,CAAC,CAAC,CAACC,iBAAiB,CAAC,CAAC,CAACC,mBAAmB,CAAC,CAAC;UAClJ,IAAIJ,UAAU,CAAClB,MAAM,GAAG,CAAC,EAAE;YACzB,MAAMuB,QAAQ,GAAGL,UAAU,CAAC,CAAC,CAAC,CAACM,WAAW;YAC1C,MAAMC,QAAQ,GAAGf,IAAI,CAACgB,GAAG,CAAC,GAAGC,MAAM,CAACC,MAAM,CAACL,QAAQ,CAAC,CAAC;YACrD,MAAMM,OAAO,GAAGF,MAAM,CAACG,IAAI,CAACP,QAAQ,CAAC,CAACQ,IAAI,CAACC,GAAG,IAAIT,QAAQ,CAACS,GAAG,CAAC,KAAKP,QAAQ,CAAC;YAC7E3D,UAAU,CAAC+D,OAAO,CAAC;UACrB;QACF;MACF,CAAC;IACH,CAAC;IAED3D,iBAAiB,CAAC,CAAC,CAAC+D,IAAI,CAACxD,sBAAsB,CAAC;IAEhD,OAAO,MAAM;MACX,IAAIV,QAAQ,CAACsB,OAAO,IAAItB,QAAQ,CAACsB,OAAO,CAAC6C,SAAS,EAAE;QAClDnE,QAAQ,CAACsB,OAAO,CAAC6C,SAAS,CAACC,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;MACvE;IACF,CAAC;EACH,CAAC,EAAE,CAACzE,WAAW,EAAEC,UAAU,EAAEE,cAAc,CAAC,CAAC;EAE7C,oBACEP,OAAA;IAAA8E,QAAA,eACE9E,OAAA;MAAO+E,GAAG,EAAEzE,QAAS;MAAC0E,QAAQ;MAACC,KAAK;MAAC/C,KAAK,EAAC,KAAK;MAACC,MAAM,EAAC;IAAK;MAAA+C,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAC7D,CAAC;AAEV,CAAC;AAAClF,EAAA,CApGIF,2BAA2B;AAAAqF,EAAA,GAA3BrF,2BAA2B;AAsGjC,eAAeA,2BAA2B;AAAC,IAAAqF,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}