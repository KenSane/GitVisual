{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\janry\\\\Music\\\\VisualQuery\\\\frontend\\\\src\\\\component\\\\EmotionDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useRef, useEffect } from 'react';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst EmotionDetection = _ref => {\n  _s();\n  let {\n    setEmotion\n  } = _ref;\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = '/models';\n      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\n      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);\n      await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);\n      await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);\n    };\n    loadModels();\n    const startVideo = () => {\n      navigator.getUserMedia({\n        video: {}\n      }, stream => videoRef.current.srcObject = stream, err => console.error(err));\n    };\n    videoRef.current && startVideo();\n    const handleVideoOnPlay = () => {\n      setInterval(async () => {\n        if (!videoRef.current || !canvasRef.current) return;\n        const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n        if (detections.length > 0) {\n          const emotion = detections[0].expressions.asSortedArray()[0].expression;\n          setEmotion(emotion);\n        }\n        const displaySize = {\n          width: videoRef.current.videoWidth,\n          height: videoRef.current.videoHeight\n        };\n        faceapi.matchDimensions(canvasRef.current, displaySize);\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\n        canvasRef.current.getContext('2d').clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);\n        faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\n        faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\n        faceapi.draw.drawFaceExpressions(canvasRef.current, resizedDetections);\n      }, 100);\n    };\n    videoRef.current && videoRef.current.addEventListener('play', handleVideoOnPlay);\n  }, [setEmotion]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true,\n      muted: true,\n      width: \"640\",\n      height: \"480\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 62,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 61,\n    columnNumber: 5\n  }, this);\n};\n_s(EmotionDetection, \"0gwqVvoOV2or9Ql4L8GH2BGn3hc=\");\n_c = EmotionDetection;\nexport default EmotionDetection;\nvar _c;\n$RefreshReg$(_c, \"EmotionDetection\");","map":{"version":3,"names":["React","useRef","useEffect","faceapi","jsxDEV","_jsxDEV","EmotionDetection","_ref","_s","setEmotion","videoRef","canvasRef","loadModels","MODEL_URL","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","startVideo","navigator","getUserMedia","video","stream","current","srcObject","err","console","error","handleVideoOnPlay","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","length","emotion","expressions","asSortedArray","expression","displaySize","width","videoWidth","height","videoHeight","matchDimensions","resizedDetections","resizeResults","getContext","clearRect","draw","drawDetections","drawFaceLandmarks","drawFaceExpressions","addEventListener","children","ref","autoPlay","muted","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/janry/Music/VisualQuery/frontend/src/component/EmotionDetection.js"],"sourcesContent":["import React, { useRef, useEffect } from 'react';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst EmotionDetection = ({ setEmotion }) => {\r\n  const videoRef = useRef(null);\r\n  const canvasRef = useRef(null);\r\n\r\n  useEffect(() => {\r\n    const loadModels = async () => {\r\n      const MODEL_URL = '/models';\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\r\n      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);\r\n      await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);\r\n      await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);\r\n    };\r\n\r\n    loadModels();\r\n\r\n    const startVideo = () => {\r\n      navigator.getUserMedia(\r\n        { video: {} },\r\n        stream => (videoRef.current.srcObject = stream),\r\n        err => console.error(err)\r\n      );\r\n    };\r\n\r\n    videoRef.current && startVideo();\r\n\r\n    const handleVideoOnPlay = () => {\r\n      setInterval(async () => {\r\n        if (!videoRef.current || !canvasRef.current) return;\r\n\r\n        const detections = await faceapi.detectAllFaces(\r\n          videoRef.current,\r\n          new faceapi.TinyFaceDetectorOptions()\r\n        ).withFaceLandmarks().withFaceExpressions();\r\n\r\n        if (detections.length > 0) {\r\n          const emotion = detections[0].expressions.asSortedArray()[0].expression;\r\n          setEmotion(emotion);\r\n        }\r\n\r\n        const displaySize = {\r\n          width: videoRef.current.videoWidth,\r\n          height: videoRef.current.videoHeight,\r\n        };\r\n        faceapi.matchDimensions(canvasRef.current, displaySize);\r\n\r\n        const resizedDetections = faceapi.resizeResults(detections, displaySize);\r\n        canvasRef.current.getContext('2d').clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);\r\n        faceapi.draw.drawDetections(canvasRef.current, resizedDetections);\r\n        faceapi.draw.drawFaceLandmarks(canvasRef.current, resizedDetections);\r\n        faceapi.draw.drawFaceExpressions(canvasRef.current, resizedDetections);\r\n      }, 100);\r\n    };\r\n\r\n    videoRef.current && videoRef.current.addEventListener('play', handleVideoOnPlay);\r\n  }, [setEmotion]);\r\n\r\n  return (\r\n    <div>\r\n      <video ref={videoRef} autoPlay muted width=\"640\" height=\"480\" />\r\n      <canvas ref={canvasRef} />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default EmotionDetection;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAChD,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,gBAAgB,GAAGC,IAAA,IAAoB;EAAAC,EAAA;EAAA,IAAnB;IAAEC;EAAW,CAAC,GAAAF,IAAA;EACtC,MAAMG,QAAQ,GAAGT,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMU,SAAS,GAAGV,MAAM,CAAC,IAAI,CAAC;EAE9BC,SAAS,CAAC,MAAM;IACd,MAAMU,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMC,SAAS,GAAG,SAAS;MAC3B,MAAMV,OAAO,CAACW,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAACH,SAAS,CAAC;MAC1D,MAAMV,OAAO,CAACW,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAACH,SAAS,CAAC;MAC3D,MAAMV,OAAO,CAACW,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAACH,SAAS,CAAC;MAC5D,MAAMV,OAAO,CAACW,IAAI,CAACK,iBAAiB,CAACH,WAAW,CAACH,SAAS,CAAC;IAC7D,CAAC;IAEDD,UAAU,CAAC,CAAC;IAEZ,MAAMQ,UAAU,GAAGA,CAAA,KAAM;MACvBC,SAAS,CAACC,YAAY,CACpB;QAAEC,KAAK,EAAE,CAAC;MAAE,CAAC,EACbC,MAAM,IAAKd,QAAQ,CAACe,OAAO,CAACC,SAAS,GAAGF,MAAO,EAC/CG,GAAG,IAAIC,OAAO,CAACC,KAAK,CAACF,GAAG,CAC1B,CAAC;IACH,CAAC;IAEDjB,QAAQ,CAACe,OAAO,IAAIL,UAAU,CAAC,CAAC;IAEhC,MAAMU,iBAAiB,GAAGA,CAAA,KAAM;MAC9BC,WAAW,CAAC,YAAY;QACtB,IAAI,CAACrB,QAAQ,CAACe,OAAO,IAAI,CAACd,SAAS,CAACc,OAAO,EAAE;QAE7C,MAAMO,UAAU,GAAG,MAAM7B,OAAO,CAAC8B,cAAc,CAC7CvB,QAAQ,CAACe,OAAO,EAChB,IAAItB,OAAO,CAAC+B,uBAAuB,CAAC,CACtC,CAAC,CAACC,iBAAiB,CAAC,CAAC,CAACC,mBAAmB,CAAC,CAAC;QAE3C,IAAIJ,UAAU,CAACK,MAAM,GAAG,CAAC,EAAE;UACzB,MAAMC,OAAO,GAAGN,UAAU,CAAC,CAAC,CAAC,CAACO,WAAW,CAACC,aAAa,CAAC,CAAC,CAAC,CAAC,CAAC,CAACC,UAAU;UACvEhC,UAAU,CAAC6B,OAAO,CAAC;QACrB;QAEA,MAAMI,WAAW,GAAG;UAClBC,KAAK,EAAEjC,QAAQ,CAACe,OAAO,CAACmB,UAAU;UAClCC,MAAM,EAAEnC,QAAQ,CAACe,OAAO,CAACqB;QAC3B,CAAC;QACD3C,OAAO,CAAC4C,eAAe,CAACpC,SAAS,CAACc,OAAO,EAAEiB,WAAW,CAAC;QAEvD,MAAMM,iBAAiB,GAAG7C,OAAO,CAAC8C,aAAa,CAACjB,UAAU,EAAEU,WAAW,CAAC;QACxE/B,SAAS,CAACc,OAAO,CAACyB,UAAU,CAAC,IAAI,CAAC,CAACC,SAAS,CAAC,CAAC,EAAE,CAAC,EAAExC,SAAS,CAACc,OAAO,CAACkB,KAAK,EAAEhC,SAAS,CAACc,OAAO,CAACoB,MAAM,CAAC;QACrG1C,OAAO,CAACiD,IAAI,CAACC,cAAc,CAAC1C,SAAS,CAACc,OAAO,EAAEuB,iBAAiB,CAAC;QACjE7C,OAAO,CAACiD,IAAI,CAACE,iBAAiB,CAAC3C,SAAS,CAACc,OAAO,EAAEuB,iBAAiB,CAAC;QACpE7C,OAAO,CAACiD,IAAI,CAACG,mBAAmB,CAAC5C,SAAS,CAACc,OAAO,EAAEuB,iBAAiB,CAAC;MACxE,CAAC,EAAE,GAAG,CAAC;IACT,CAAC;IAEDtC,QAAQ,CAACe,OAAO,IAAIf,QAAQ,CAACe,OAAO,CAAC+B,gBAAgB,CAAC,MAAM,EAAE1B,iBAAiB,CAAC;EAClF,CAAC,EAAE,CAACrB,UAAU,CAAC,CAAC;EAEhB,oBACEJ,OAAA;IAAAoD,QAAA,gBACEpD,OAAA;MAAOqD,GAAG,EAAEhD,QAAS;MAACiD,QAAQ;MAACC,KAAK;MAACjB,KAAK,EAAC,KAAK;MAACE,MAAM,EAAC;IAAK;MAAAgB,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eAChE3D,OAAA;MAAQqD,GAAG,EAAE/C;IAAU;MAAAkD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACvB,CAAC;AAEV,CAAC;AAACxD,EAAA,CA9DIF,gBAAgB;AAAA2D,EAAA,GAAhB3D,gBAAgB;AAgEtB,eAAeA,gBAAgB;AAAC,IAAA2D,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}