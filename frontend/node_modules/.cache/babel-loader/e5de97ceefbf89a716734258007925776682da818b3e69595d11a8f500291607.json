{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\janry\\\\Music\\\\VisualQuery\\\\frontend\\\\src\\\\component\\\\RealTimePessimism.js\",\n  _s = $RefreshSig$();\nimport React, { useRef, useEffect } from 'react';\nimport * as mp from '@mediapipe/face_mesh';\nimport * as cam from '@mediapipe/camera_utils';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst HeadPoseAndEmotionDetection = _ref => {\n  _s();\n  let {\n    setHeadPose,\n    setEmotion\n  } = _ref;\n  const videoRef = useRef(null);\n  useEffect(() => {\n    const faceMesh = new mp.FaceMesh({\n      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`\n    });\n    faceMesh.setOptions({\n      maxNumFaces: 1,\n      refineLandmarks: true,\n      minDetectionConfidence: 0.5,\n      minTrackingConfidence: 0.5\n    });\n    faceMesh.onResults(onResults);\n    let camera;\n    if (typeof videoRef.current !== 'undefined' && videoRef.current !== null) {\n      camera = new cam.Camera(videoRef.current, {\n        onFrame: async () => {\n          await faceMesh.send({\n            image: videoRef.current\n          });\n        },\n        width: 640,\n        height: 480\n      });\n      camera.start();\n    }\n    const loadFaceApiModels = async () => {\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\n    };\n    const startVideoAndDetection = async () => {\n      await loadFaceApiModels();\n      if (videoRef.current) {\n        navigator.mediaDevices.getUserMedia({\n          video: {}\n        }).then(stream => {\n          videoRef.current.srcObject = stream;\n        }).catch(err => console.error('Error accessing webcam: ', err));\n        const intervalId = setInterval(detectEmotion, 1000); // Check for emotions every second\n\n        function onResults(results) {\n          if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {\n            const landmarks = results.multiFaceLandmarks[0];\n            const noseTip = landmarks[1];\n            const leftCheek = landmarks[33];\n            const rightCheek = landmarks[263];\n            const dx = rightCheek.x - leftCheek.x;\n            const dy = rightCheek.y - leftCheek.y;\n            const angleY = Math.atan2(dy, dx) * (180 / Math.PI);\n            const noseBottom = landmarks[2];\n            const chin = landmarks[152];\n            const dz = chin.y - noseBottom.y;\n            const angleX = Math.atan2(dz, dx) * (180 / Math.PI);\n            let pose = 'forward';\n            if (angleY < -10) {\n              pose = 'left';\n            } else if (angleX > 17) {\n              pose = 'up';\n            } else if (angleX < -1) {\n              pose = 'down';\n            }\n            setHeadPose(pose);\n          }\n        }\n        const detectEmotion = async () => {\n          if (videoRef.current) {\n            const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n            if (detections.length > 0) {\n              const emotions = detections[0].expressions;\n              const maxValue = Math.max(...Object.values(emotions));\n              const emotion = Object.keys(emotions).find(key => emotions[key] === maxValue);\n              setEmotion(emotion);\n            }\n          }\n        };\n        return () => {\n          clearInterval(intervalId);\n          if (videoRef.current && videoRef.current.srcObject) {\n            videoRef.current.srcObject.getTracks().forEach(track => track.stop());\n          }\n        };\n      }\n    };\n    startVideoAndDetection();\n  }, [setHeadPose, setEmotion]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true,\n      muted: true,\n      width: \"640\",\n      height: \"480\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 111,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 110,\n    columnNumber: 5\n  }, this);\n};\n_s(HeadPoseAndEmotionDetection, \"PdMsmLAy5JKU3vCrhAlqGYQfKuA=\");\n_c = HeadPoseAndEmotionDetection;\nexport default HeadPoseAndEmotionDetection;\nvar _c;\n$RefreshReg$(_c, \"HeadPoseAndEmotionDetection\");","map":{"version":3,"names":["React","useRef","useEffect","mp","cam","faceapi","jsxDEV","_jsxDEV","HeadPoseAndEmotionDetection","_ref","_s","setHeadPose","setEmotion","videoRef","faceMesh","FaceMesh","locateFile","file","setOptions","maxNumFaces","refineLandmarks","minDetectionConfidence","minTrackingConfidence","onResults","camera","current","Camera","onFrame","send","image","width","height","start","loadFaceApiModels","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","startVideoAndDetection","navigator","mediaDevices","getUserMedia","video","then","stream","srcObject","catch","err","console","error","intervalId","setInterval","detectEmotion","results","multiFaceLandmarks","length","landmarks","noseTip","leftCheek","rightCheek","dx","x","dy","y","angleY","Math","atan2","PI","noseBottom","chin","dz","angleX","pose","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","emotions","expressions","maxValue","max","Object","values","emotion","keys","find","key","clearInterval","getTracks","forEach","track","stop","children","ref","autoPlay","muted","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/janry/Music/VisualQuery/frontend/src/component/RealTimePessimism.js"],"sourcesContent":["import React, { useRef, useEffect } from 'react';\r\nimport * as mp from '@mediapipe/face_mesh';\r\nimport * as cam from '@mediapipe/camera_utils';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst HeadPoseAndEmotionDetection = ({ setHeadPose, setEmotion }) => {\r\n  const videoRef = useRef(null);\r\n\r\n  useEffect(() => {\r\n    const faceMesh = new mp.FaceMesh({\r\n      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,\r\n    });\r\n\r\n    faceMesh.setOptions({\r\n      maxNumFaces: 1,\r\n      refineLandmarks: true,\r\n      minDetectionConfidence: 0.5,\r\n      minTrackingConfidence: 0.5,\r\n    });\r\n\r\n    faceMesh.onResults(onResults);\r\n\r\n    let camera;\r\n    if (typeof videoRef.current !== 'undefined' && videoRef.current !== null) {\r\n      camera = new cam.Camera(videoRef.current, {\r\n        onFrame: async () => {\r\n          await faceMesh.send({ image: videoRef.current });\r\n        },\r\n        width: 640,\r\n        height: 480,\r\n      });\r\n      camera.start();\r\n    }\r\n\r\n    const loadFaceApiModels = async () => {\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\r\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\r\n      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\r\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\r\n    };\r\n\r\n    const startVideoAndDetection = async () => {\r\n      await loadFaceApiModels();\r\n\r\n      if (videoRef.current) {\r\n        navigator.mediaDevices.getUserMedia({ video: {} })\r\n          .then(stream => {\r\n            videoRef.current.srcObject = stream;\r\n          })\r\n          .catch(err => console.error('Error accessing webcam: ', err));\r\n\r\n        const intervalId = setInterval(detectEmotion, 1000); // Check for emotions every second\r\n\r\n        function onResults(results) {\r\n          if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {\r\n            const landmarks = results.multiFaceLandmarks[0];\r\n\r\n            const noseTip = landmarks[1];\r\n            const leftCheek = landmarks[33];\r\n            const rightCheek = landmarks[263];\r\n\r\n            const dx = rightCheek.x - leftCheek.x;\r\n            const dy = rightCheek.y - leftCheek.y;\r\n            const angleY = Math.atan2(dy, dx) * (180 / Math.PI);\r\n\r\n            const noseBottom = landmarks[2];\r\n            const chin = landmarks[152];\r\n\r\n            const dz = chin.y - noseBottom.y;\r\n            const angleX = Math.atan2(dz, dx) * (180 / Math.PI);\r\n\r\n            let pose = 'forward';\r\n            if (angleY < -10) {\r\n              pose = 'left';\r\n            } else if (angleX > 17) {\r\n              pose = 'up';\r\n            } else if (angleX < -1) {\r\n              pose = 'down';\r\n            }\r\n\r\n            setHeadPose(pose);\r\n          }\r\n        }\r\n\r\n        const detectEmotion = async () => {\r\n          if (videoRef.current) {\r\n            const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\r\n            if (detections.length > 0) {\r\n              const emotions = detections[0].expressions;\r\n              const maxValue = Math.max(...Object.values(emotions));\r\n              const emotion = Object.keys(emotions).find(key => emotions[key] === maxValue);\r\n              setEmotion(emotion);\r\n            }\r\n          }\r\n        };\r\n\r\n        return () => {\r\n          clearInterval(intervalId);\r\n          if (videoRef.current && videoRef.current.srcObject) {\r\n            videoRef.current.srcObject.getTracks().forEach(track => track.stop());\r\n          }\r\n        };\r\n      }\r\n    };\r\n\r\n    startVideoAndDetection();\r\n  }, [setHeadPose, setEmotion]);\r\n\r\n  return (\r\n    <div>\r\n      <video ref={videoRef} autoPlay muted width=\"640\" height=\"480\" />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default HeadPoseAndEmotionDetection;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAChD,OAAO,KAAKC,EAAE,MAAM,sBAAsB;AAC1C,OAAO,KAAKC,GAAG,MAAM,yBAAyB;AAC9C,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,2BAA2B,GAAGC,IAAA,IAAiC;EAAAC,EAAA;EAAA,IAAhC;IAAEC,WAAW;IAAEC;EAAW,CAAC,GAAAH,IAAA;EAC9D,MAAMI,QAAQ,GAAGZ,MAAM,CAAC,IAAI,CAAC;EAE7BC,SAAS,CAAC,MAAM;IACd,MAAMY,QAAQ,GAAG,IAAIX,EAAE,CAACY,QAAQ,CAAC;MAC/BC,UAAU,EAAGC,IAAI,IAAM,qDAAoDA,IAAK;IAClF,CAAC,CAAC;IAEFH,QAAQ,CAACI,UAAU,CAAC;MAClBC,WAAW,EAAE,CAAC;MACdC,eAAe,EAAE,IAAI;MACrBC,sBAAsB,EAAE,GAAG;MAC3BC,qBAAqB,EAAE;IACzB,CAAC,CAAC;IAEFR,QAAQ,CAACS,SAAS,CAACA,SAAS,CAAC;IAE7B,IAAIC,MAAM;IACV,IAAI,OAAOX,QAAQ,CAACY,OAAO,KAAK,WAAW,IAAIZ,QAAQ,CAACY,OAAO,KAAK,IAAI,EAAE;MACxED,MAAM,GAAG,IAAIpB,GAAG,CAACsB,MAAM,CAACb,QAAQ,CAACY,OAAO,EAAE;QACxCE,OAAO,EAAE,MAAAA,CAAA,KAAY;UACnB,MAAMb,QAAQ,CAACc,IAAI,CAAC;YAAEC,KAAK,EAAEhB,QAAQ,CAACY;UAAQ,CAAC,CAAC;QAClD,CAAC;QACDK,KAAK,EAAE,GAAG;QACVC,MAAM,EAAE;MACV,CAAC,CAAC;MACFP,MAAM,CAACQ,KAAK,CAAC,CAAC;IAChB;IAEA,MAAMC,iBAAiB,GAAG,MAAAA,CAAA,KAAY;MACpC,MAAM5B,OAAO,CAAC6B,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;MAC1D,MAAM/B,OAAO,CAAC6B,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC;MAC3D,MAAM/B,OAAO,CAAC6B,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAAC,SAAS,CAAC;MAC5D,MAAM/B,OAAO,CAAC6B,IAAI,CAACK,iBAAiB,CAACH,WAAW,CAAC,SAAS,CAAC;IAC7D,CAAC;IAED,MAAMI,sBAAsB,GAAG,MAAAA,CAAA,KAAY;MACzC,MAAMP,iBAAiB,CAAC,CAAC;MAEzB,IAAIpB,QAAQ,CAACY,OAAO,EAAE;QACpBgB,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;UAAEC,KAAK,EAAE,CAAC;QAAE,CAAC,CAAC,CAC/CC,IAAI,CAACC,MAAM,IAAI;UACdjC,QAAQ,CAACY,OAAO,CAACsB,SAAS,GAAGD,MAAM;QACrC,CAAC,CAAC,CACDE,KAAK,CAACC,GAAG,IAAIC,OAAO,CAACC,KAAK,CAAC,0BAA0B,EAAEF,GAAG,CAAC,CAAC;QAE/D,MAAMG,UAAU,GAAGC,WAAW,CAACC,aAAa,EAAE,IAAI,CAAC,CAAC,CAAC;;QAErD,SAAS/B,SAASA,CAACgC,OAAO,EAAE;UAC1B,IAAIA,OAAO,CAACC,kBAAkB,IAAID,OAAO,CAACC,kBAAkB,CAACC,MAAM,GAAG,CAAC,EAAE;YACvE,MAAMC,SAAS,GAAGH,OAAO,CAACC,kBAAkB,CAAC,CAAC,CAAC;YAE/C,MAAMG,OAAO,GAAGD,SAAS,CAAC,CAAC,CAAC;YAC5B,MAAME,SAAS,GAAGF,SAAS,CAAC,EAAE,CAAC;YAC/B,MAAMG,UAAU,GAAGH,SAAS,CAAC,GAAG,CAAC;YAEjC,MAAMI,EAAE,GAAGD,UAAU,CAACE,CAAC,GAAGH,SAAS,CAACG,CAAC;YACrC,MAAMC,EAAE,GAAGH,UAAU,CAACI,CAAC,GAAGL,SAAS,CAACK,CAAC;YACrC,MAAMC,MAAM,GAAGC,IAAI,CAACC,KAAK,CAACJ,EAAE,EAAEF,EAAE,CAAC,IAAI,GAAG,GAAGK,IAAI,CAACE,EAAE,CAAC;YAEnD,MAAMC,UAAU,GAAGZ,SAAS,CAAC,CAAC,CAAC;YAC/B,MAAMa,IAAI,GAAGb,SAAS,CAAC,GAAG,CAAC;YAE3B,MAAMc,EAAE,GAAGD,IAAI,CAACN,CAAC,GAAGK,UAAU,CAACL,CAAC;YAChC,MAAMQ,MAAM,GAAGN,IAAI,CAACC,KAAK,CAACI,EAAE,EAAEV,EAAE,CAAC,IAAI,GAAG,GAAGK,IAAI,CAACE,EAAE,CAAC;YAEnD,IAAIK,IAAI,GAAG,SAAS;YACpB,IAAIR,MAAM,GAAG,CAAC,EAAE,EAAE;cAChBQ,IAAI,GAAG,MAAM;YACf,CAAC,MAAM,IAAID,MAAM,GAAG,EAAE,EAAE;cACtBC,IAAI,GAAG,IAAI;YACb,CAAC,MAAM,IAAID,MAAM,GAAG,CAAC,CAAC,EAAE;cACtBC,IAAI,GAAG,MAAM;YACf;YAEA/D,WAAW,CAAC+D,IAAI,CAAC;UACnB;QACF;QAEA,MAAMpB,aAAa,GAAG,MAAAA,CAAA,KAAY;UAChC,IAAIzC,QAAQ,CAACY,OAAO,EAAE;YACpB,MAAMkD,UAAU,GAAG,MAAMtE,OAAO,CAACuE,cAAc,CAAC/D,QAAQ,CAACY,OAAO,EAAE,IAAIpB,OAAO,CAACwE,uBAAuB,CAAC,CAAC,CAAC,CAACC,iBAAiB,CAAC,CAAC,CAACC,mBAAmB,CAAC,CAAC;YAClJ,IAAIJ,UAAU,CAAClB,MAAM,GAAG,CAAC,EAAE;cACzB,MAAMuB,QAAQ,GAAGL,UAAU,CAAC,CAAC,CAAC,CAACM,WAAW;cAC1C,MAAMC,QAAQ,GAAGf,IAAI,CAACgB,GAAG,CAAC,GAAGC,MAAM,CAACC,MAAM,CAACL,QAAQ,CAAC,CAAC;cACrD,MAAMM,OAAO,GAAGF,MAAM,CAACG,IAAI,CAACP,QAAQ,CAAC,CAACQ,IAAI,CAACC,GAAG,IAAIT,QAAQ,CAACS,GAAG,CAAC,KAAKP,QAAQ,CAAC;cAC7EtE,UAAU,CAAC0E,OAAO,CAAC;YACrB;UACF;QACF,CAAC;QAED,OAAO,MAAM;UACXI,aAAa,CAACtC,UAAU,CAAC;UACzB,IAAIvC,QAAQ,CAACY,OAAO,IAAIZ,QAAQ,CAACY,OAAO,CAACsB,SAAS,EAAE;YAClDlC,QAAQ,CAACY,OAAO,CAACsB,SAAS,CAAC4C,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;UACvE;QACF,CAAC;MACH;IACF,CAAC;IAEDtD,sBAAsB,CAAC,CAAC;EAC1B,CAAC,EAAE,CAAC7B,WAAW,EAAEC,UAAU,CAAC,CAAC;EAE7B,oBACEL,OAAA;IAAAwF,QAAA,eACExF,OAAA;MAAOyF,GAAG,EAAEnF,QAAS;MAACoF,QAAQ;MAACC,KAAK;MAACpE,KAAK,EAAC,KAAK;MAACC,MAAM,EAAC;IAAK;MAAAoE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAC7D,CAAC;AAEV,CAAC;AAAC5F,EAAA,CA5GIF,2BAA2B;AAAA+F,EAAA,GAA3B/F,2BAA2B;AA8GjC,eAAeA,2BAA2B;AAAC,IAAA+F,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}