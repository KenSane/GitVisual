{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\janry\\\\Music\\\\VisualQuery\\\\frontend\\\\src\\\\component\\\\EmotionDetection.js\",\n  _s = $RefreshSig$();\n// EmotionDetection.js\n\nimport React, { useEffect } from 'react';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst EmotionDetection = _ref => {\n  _s();\n  let {\n    setEmotion\n  } = _ref;\n  useEffect(() => {\n    const video = document.getElementById('video');\n    const loadModels = async () => {\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\n      startVideo();\n    };\n    const startVideo = () => {\n      navigator.getUserMedia({\n        video: {}\n      }, stream => video.srcObject = stream, err => console.error(err));\n    };\n    const handleVideoOnPlay = () => {\n      setInterval(async () => {\n        if (!video || video.paused || video.ended) return;\n        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n        if (detections.length > 0) {\n          const emotion = Object.keys(detections[0].expressions).reduce((a, b) => detections[0].expressions[a] > detections[0].expressions[b] ? a : b);\n          setEmotion(emotion);\n          console.log(\"Detected emotion:\", emotion); // Log detected emotion for debugging\n        } else {\n          console.log(\"No face detected or unable to detect emotion\");\n        }\n      }, 1000);\n    };\n    video.addEventListener('play', handleVideoOnPlay);\n    loadModels();\n  }, [setEmotion]);\n  return /*#__PURE__*/_jsxDEV(\"video\", {\n    id: \"video\",\n    width: \"720\",\n    height: \"560\",\n    autoPlay: true,\n    muted: true\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 50,\n    columnNumber: 10\n  }, this);\n};\n_s(EmotionDetection, \"OD7bBpZva5O2jO+Puf00hKivP7c=\");\n_c = EmotionDetection;\nexport default EmotionDetection;\nvar _c;\n$RefreshReg$(_c, \"EmotionDetection\");","map":{"version":3,"names":["React","useEffect","faceapi","jsxDEV","_jsxDEV","EmotionDetection","_ref","_s","setEmotion","video","document","getElementById","loadModels","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceExpressionNet","startVideo","navigator","getUserMedia","stream","srcObject","err","console","error","handleVideoOnPlay","setInterval","paused","ended","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","length","emotion","Object","keys","expressions","reduce","a","b","log","addEventListener","id","width","height","autoPlay","muted","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/janry/Music/VisualQuery/frontend/src/component/EmotionDetection.js"],"sourcesContent":["// EmotionDetection.js\r\n\r\nimport React, { useEffect } from 'react';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst EmotionDetection = ({ setEmotion }) => {\r\n  useEffect(() => {\r\n    const video = document.getElementById('video');\r\n\r\n    const loadModels = async () => {\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\r\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\r\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\r\n      startVideo();\r\n    };\r\n\r\n    const startVideo = () => {\r\n      navigator.getUserMedia(\r\n        { video: {} },\r\n        stream => (video.srcObject = stream),\r\n        err => console.error(err)\r\n      );\r\n    };\r\n\r\n    const handleVideoOnPlay = () => {\r\n      setInterval(async () => {\r\n        if (!video || video.paused || video.ended) return;\r\n\r\n        const detections = await faceapi\r\n          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())\r\n          .withFaceLandmarks()\r\n          .withFaceExpressions();\r\n\r\n        if (detections.length > 0) {\r\n          const emotion = Object.keys(detections[0].expressions).reduce((a, b) =>\r\n            detections[0].expressions[a] > detections[0].expressions[b] ? a : b\r\n          );\r\n          setEmotion(emotion);\r\n          console.log(\"Detected emotion:\", emotion);  // Log detected emotion for debugging\r\n        } else {\r\n          console.log(\"No face detected or unable to detect emotion\");\r\n        }\r\n      }, 1000);\r\n    };\r\n\r\n    video.addEventListener('play', handleVideoOnPlay);\r\n    loadModels();\r\n  }, [setEmotion]);\r\n\r\n  return <video id=\"video\" width=\"720\" height=\"560\" autoPlay muted />;\r\n};\r\n\r\nexport default EmotionDetection;\r\n"],"mappings":";;AAAA;;AAEA,OAAOA,KAAK,IAAIC,SAAS,QAAQ,OAAO;AACxC,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,gBAAgB,GAAGC,IAAA,IAAoB;EAAAC,EAAA;EAAA,IAAnB;IAAEC;EAAW,CAAC,GAAAF,IAAA;EACtCL,SAAS,CAAC,MAAM;IACd,MAAMQ,KAAK,GAAGC,QAAQ,CAACC,cAAc,CAAC,OAAO,CAAC;IAE9C,MAAMC,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMV,OAAO,CAACW,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;MAC1D,MAAMb,OAAO,CAACW,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC;MAC3D,MAAMb,OAAO,CAACW,IAAI,CAACI,iBAAiB,CAACF,WAAW,CAAC,SAAS,CAAC;MAC3DG,UAAU,CAAC,CAAC;IACd,CAAC;IAED,MAAMA,UAAU,GAAGA,CAAA,KAAM;MACvBC,SAAS,CAACC,YAAY,CACpB;QAAEX,KAAK,EAAE,CAAC;MAAE,CAAC,EACbY,MAAM,IAAKZ,KAAK,CAACa,SAAS,GAAGD,MAAO,EACpCE,GAAG,IAAIC,OAAO,CAACC,KAAK,CAACF,GAAG,CAC1B,CAAC;IACH,CAAC;IAED,MAAMG,iBAAiB,GAAGA,CAAA,KAAM;MAC9BC,WAAW,CAAC,YAAY;QACtB,IAAI,CAAClB,KAAK,IAAIA,KAAK,CAACmB,MAAM,IAAInB,KAAK,CAACoB,KAAK,EAAE;QAE3C,MAAMC,UAAU,GAAG,MAAM5B,OAAO,CAC7B6B,cAAc,CAACtB,KAAK,EAAE,IAAIP,OAAO,CAAC8B,uBAAuB,CAAC,CAAC,CAAC,CAC5DC,iBAAiB,CAAC,CAAC,CACnBC,mBAAmB,CAAC,CAAC;QAExB,IAAIJ,UAAU,CAACK,MAAM,GAAG,CAAC,EAAE;UACzB,MAAMC,OAAO,GAAGC,MAAM,CAACC,IAAI,CAACR,UAAU,CAAC,CAAC,CAAC,CAACS,WAAW,CAAC,CAACC,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KACjEZ,UAAU,CAAC,CAAC,CAAC,CAACS,WAAW,CAACE,CAAC,CAAC,GAAGX,UAAU,CAAC,CAAC,CAAC,CAACS,WAAW,CAACG,CAAC,CAAC,GAAGD,CAAC,GAAGC,CACpE,CAAC;UACDlC,UAAU,CAAC4B,OAAO,CAAC;UACnBZ,OAAO,CAACmB,GAAG,CAAC,mBAAmB,EAAEP,OAAO,CAAC,CAAC,CAAE;QAC9C,CAAC,MAAM;UACLZ,OAAO,CAACmB,GAAG,CAAC,8CAA8C,CAAC;QAC7D;MACF,CAAC,EAAE,IAAI,CAAC;IACV,CAAC;IAEDlC,KAAK,CAACmC,gBAAgB,CAAC,MAAM,EAAElB,iBAAiB,CAAC;IACjDd,UAAU,CAAC,CAAC;EACd,CAAC,EAAE,CAACJ,UAAU,CAAC,CAAC;EAEhB,oBAAOJ,OAAA;IAAOyC,EAAE,EAAC,OAAO;IAACC,KAAK,EAAC,KAAK;IAACC,MAAM,EAAC,KAAK;IAACC,QAAQ;IAACC,KAAK;EAAA;IAAAC,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAAE,CAAC;AACrE,CAAC;AAAC9C,EAAA,CA7CIF,gBAAgB;AAAAiD,EAAA,GAAhBjD,gBAAgB;AA+CtB,eAAeA,gBAAgB;AAAC,IAAAiD,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}