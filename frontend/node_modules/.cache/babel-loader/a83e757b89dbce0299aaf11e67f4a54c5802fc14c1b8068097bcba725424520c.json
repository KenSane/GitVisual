{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\janry\\\\Music\\\\VisualQuery\\\\frontend\\\\src\\\\component\\\\EmotionDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useRef, useEffect } from 'react';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst EmotionDetection = _ref => {\n  _s();\n  let {\n    setEmotion\n  } = _ref;\n  const videoRef = useRef(null);\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = '/models';\n      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\n      await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);\n    };\n    const startVideo = () => {\n      navigator.mediaDevices.getUserMedia({\n        video: {}\n      }).then(stream => {\n        videoRef.current.srcObject = stream;\n      }).catch(err => {\n        console.error('Error accessing webcam: ', err);\n      });\n    };\n    const handleVideoOnPlay = () => {\n      setInterval(async () => {\n        if (videoRef.current) {\n          const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();\n          if (detections.length > 0) {\n            const emotions = detections[0].expressions;\n            const maxEmotion = Object.keys(emotions).reduce((a, b) => emotions[a] > emotions[b] ? a : b);\n            setEmotion(maxEmotion);\n          }\n        }\n      }, 1000);\n    };\n    const initialize = async () => {\n      await loadModels();\n      startVideo();\n    };\n    initialize();\n    return () => {\n      if (videoRef.current && videoRef.current.srcObject) {\n        videoRef.current.srcObject.getTracks().forEach(track => track.stop());\n      }\n    };\n  }, [setEmotion]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true,\n      muted: true,\n      onPlay: handleVideoOnPlay,\n      style: {\n        display: 'none'\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 57,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 56,\n    columnNumber: 5\n  }, this);\n};\n_s(EmotionDetection, \"PdMsmLAy5JKU3vCrhAlqGYQfKuA=\");\n_c = EmotionDetection;\nexport default EmotionDetection;\nvar _c;\n$RefreshReg$(_c, \"EmotionDetection\");","map":{"version":3,"names":["React","useRef","useEffect","faceapi","jsxDEV","_jsxDEV","EmotionDetection","_ref","_s","setEmotion","videoRef","loadModels","MODEL_URL","nets","tinyFaceDetector","loadFromUri","faceExpressionNet","startVideo","navigator","mediaDevices","getUserMedia","video","then","stream","current","srcObject","catch","err","console","error","handleVideoOnPlay","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceExpressions","length","emotions","expressions","maxEmotion","Object","keys","reduce","a","b","initialize","getTracks","forEach","track","stop","children","ref","autoPlay","muted","onPlay","style","display","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/janry/Music/VisualQuery/frontend/src/component/EmotionDetection.js"],"sourcesContent":["import React, { useRef, useEffect } from 'react';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst EmotionDetection = ({ setEmotion }) => {\r\n  const videoRef = useRef(null);\r\n\r\n  useEffect(() => {\r\n    const loadModels = async () => {\r\n      const MODEL_URL = '/models';\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\r\n      await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);\r\n    };\r\n\r\n    const startVideo = () => {\r\n      navigator.mediaDevices.getUserMedia({ video: {} })\r\n        .then((stream) => {\r\n          videoRef.current.srcObject = stream;\r\n        })\r\n        .catch((err) => {\r\n          console.error('Error accessing webcam: ', err);\r\n        });\r\n    };\r\n\r\n    const handleVideoOnPlay = () => {\r\n      setInterval(async () => {\r\n        if (videoRef.current) {\r\n          const detections = await faceapi.detectAllFaces(\r\n            videoRef.current,\r\n            new faceapi.TinyFaceDetectorOptions()\r\n          ).withFaceExpressions();\r\n\r\n          if (detections.length > 0) {\r\n            const emotions = detections[0].expressions;\r\n            const maxEmotion = Object.keys(emotions).reduce((a, b) => emotions[a] > emotions[b] ? a : b);\r\n            setEmotion(maxEmotion);\r\n          }\r\n        }\r\n      }, 1000);\r\n    };\r\n\r\n    const initialize = async () => {\r\n      await loadModels();\r\n      startVideo();\r\n    };\r\n\r\n    initialize();\r\n\r\n    return () => {\r\n      if (videoRef.current && videoRef.current.srcObject) {\r\n        videoRef.current.srcObject.getTracks().forEach(track => track.stop());\r\n      }\r\n    };\r\n  }, [setEmotion]);\r\n\r\n  return (\r\n    <div>\r\n      <video ref={videoRef} autoPlay muted onPlay={handleVideoOnPlay} style={{ display: 'none' }} />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default EmotionDetection;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAChD,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,gBAAgB,GAAGC,IAAA,IAAoB;EAAAC,EAAA;EAAA,IAAnB;IAAEC;EAAW,CAAC,GAAAF,IAAA;EACtC,MAAMG,QAAQ,GAAGT,MAAM,CAAC,IAAI,CAAC;EAE7BC,SAAS,CAAC,MAAM;IACd,MAAMS,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMC,SAAS,GAAG,SAAS;MAC3B,MAAMT,OAAO,CAACU,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAACH,SAAS,CAAC;MAC1D,MAAMT,OAAO,CAACU,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAACH,SAAS,CAAC;IAC7D,CAAC;IAED,MAAMK,UAAU,GAAGA,CAAA,KAAM;MACvBC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE,CAAC;MAAE,CAAC,CAAC,CAC/CC,IAAI,CAAEC,MAAM,IAAK;QAChBb,QAAQ,CAACc,OAAO,CAACC,SAAS,GAAGF,MAAM;MACrC,CAAC,CAAC,CACDG,KAAK,CAAEC,GAAG,IAAK;QACdC,OAAO,CAACC,KAAK,CAAC,0BAA0B,EAAEF,GAAG,CAAC;MAChD,CAAC,CAAC;IACN,CAAC;IAED,MAAMG,iBAAiB,GAAGA,CAAA,KAAM;MAC9BC,WAAW,CAAC,YAAY;QACtB,IAAIrB,QAAQ,CAACc,OAAO,EAAE;UACpB,MAAMQ,UAAU,GAAG,MAAM7B,OAAO,CAAC8B,cAAc,CAC7CvB,QAAQ,CAACc,OAAO,EAChB,IAAIrB,OAAO,CAAC+B,uBAAuB,CAAC,CACtC,CAAC,CAACC,mBAAmB,CAAC,CAAC;UAEvB,IAAIH,UAAU,CAACI,MAAM,GAAG,CAAC,EAAE;YACzB,MAAMC,QAAQ,GAAGL,UAAU,CAAC,CAAC,CAAC,CAACM,WAAW;YAC1C,MAAMC,UAAU,GAAGC,MAAM,CAACC,IAAI,CAACJ,QAAQ,CAAC,CAACK,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKP,QAAQ,CAACM,CAAC,CAAC,GAAGN,QAAQ,CAACO,CAAC,CAAC,GAAGD,CAAC,GAAGC,CAAC,CAAC;YAC5FnC,UAAU,CAAC8B,UAAU,CAAC;UACxB;QACF;MACF,CAAC,EAAE,IAAI,CAAC;IACV,CAAC;IAED,MAAMM,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMlC,UAAU,CAAC,CAAC;MAClBM,UAAU,CAAC,CAAC;IACd,CAAC;IAED4B,UAAU,CAAC,CAAC;IAEZ,OAAO,MAAM;MACX,IAAInC,QAAQ,CAACc,OAAO,IAAId,QAAQ,CAACc,OAAO,CAACC,SAAS,EAAE;QAClDf,QAAQ,CAACc,OAAO,CAACC,SAAS,CAACqB,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;MACvE;IACF,CAAC;EACH,CAAC,EAAE,CAACxC,UAAU,CAAC,CAAC;EAEhB,oBACEJ,OAAA;IAAA6C,QAAA,eACE7C,OAAA;MAAO8C,GAAG,EAAEzC,QAAS;MAAC0C,QAAQ;MAACC,KAAK;MAACC,MAAM,EAAExB,iBAAkB;MAACyB,KAAK,EAAE;QAAEC,OAAO,EAAE;MAAO;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAC3F,CAAC;AAEV,CAAC;AAACpD,EAAA,CAxDIF,gBAAgB;AAAAuD,EAAA,GAAhBvD,gBAAgB;AA0DtB,eAAeA,gBAAgB;AAAC,IAAAuD,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}