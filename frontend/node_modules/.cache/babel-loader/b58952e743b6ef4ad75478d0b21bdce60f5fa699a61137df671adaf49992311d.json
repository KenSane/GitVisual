{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\janry\\\\Music\\\\VisualQuery\\\\frontend\\\\src\\\\component\\\\EmotionDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useRef, useEffect } from 'react';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst EmotionDetection = _ref => {\n  _s();\n  let {\n    setEmotion\n  } = _ref;\n  const videoRef = useRef(null);\n  const socketRef = useRef(null);\n  useEffect(() => {\n    const loadModels = async () => {\n      const MODEL_URL = '/models';\n      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\n      await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);\n    };\n    const startVideo = () => {\n      navigator.mediaDevices.getUserMedia({\n        video: {}\n      }).then(stream => {\n        videoRef.current.srcObject = stream;\n      }).catch(err => {\n        console.error('Error accessing webcam: ', err);\n      });\n    };\n    const handleVideoOnPlay = () => {\n      setInterval(async () => {\n        if (videoRef.current) {\n          const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();\n          if (detections.length > 0) {\n            const emotions = detections[0].expressions;\n            const maxEmotion = Object.keys(emotions).reduce((a, b) => emotions[a] > emotions[b] ? a : b);\n            setEmotion(maxEmotion);\n            sendData(maxEmotion);\n          }\n        }\n      }, 1000);\n    };\n    const initialize = async () => {\n      await loadModels();\n      startVideo();\n      videoRef.current.addEventListener('play', handleVideoOnPlay);\n    };\n    initialize();\n    return () => {\n      if (videoRef.current) {\n        videoRef.current.removeEventListener('play', handleVideoOnPlay);\n        if (videoRef.current.srcObject) {\n          videoRef.current.srcObject.getTracks().forEach(track => track.stop());\n        }\n      }\n    };\n  }, [setEmotion]);\n  const sendData = emotion => {\n    if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {\n      socketRef.current.send(JSON.stringify({\n        emotion\n      }));\n    }\n  };\n  useEffect(() => {\n    socketRef.current = new WebSocket('ws://localhost:8000/ws/pessimism_detection/');\n    socketRef.current.onopen = () => {\n      console.log('WebSocket connected');\n    };\n    socketRef.current.onclose = () => {\n      console.log('WebSocket disconnected');\n    };\n    return () => {\n      if (socketRef.current) {\n        socketRef.current.close();\n      }\n    };\n  }, []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true,\n      muted: true,\n      style: {\n        display: 'none'\n      }\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 84,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 83,\n    columnNumber: 5\n  }, this);\n};\n_s(EmotionDetection, \"QJH6maSLQIvNBelG5WbjQEu2rHU=\");\n_c = EmotionDetection;\nexport default EmotionDetection;\nvar _c;\n$RefreshReg$(_c, \"EmotionDetection\");","map":{"version":3,"names":["React","useRef","useEffect","faceapi","jsxDEV","_jsxDEV","EmotionDetection","_ref","_s","setEmotion","videoRef","socketRef","loadModels","MODEL_URL","nets","tinyFaceDetector","loadFromUri","faceExpressionNet","startVideo","navigator","mediaDevices","getUserMedia","video","then","stream","current","srcObject","catch","err","console","error","handleVideoOnPlay","setInterval","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceExpressions","length","emotions","expressions","maxEmotion","Object","keys","reduce","a","b","sendData","initialize","addEventListener","removeEventListener","getTracks","forEach","track","stop","emotion","readyState","WebSocket","OPEN","send","JSON","stringify","onopen","log","onclose","close","children","ref","autoPlay","muted","style","display","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/janry/Music/VisualQuery/frontend/src/component/EmotionDetection.js"],"sourcesContent":["import React, { useRef, useEffect } from 'react';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst EmotionDetection = ({ setEmotion }) => {\r\n  const videoRef = useRef(null);\r\n  const socketRef = useRef(null);\r\n\r\n  useEffect(() => {\r\n    const loadModels = async () => {\r\n      const MODEL_URL = '/models';\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);\r\n      await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);\r\n    };\r\n\r\n    const startVideo = () => {\r\n      navigator.mediaDevices.getUserMedia({ video: {} })\r\n        .then((stream) => {\r\n          videoRef.current.srcObject = stream;\r\n        })\r\n        .catch((err) => {\r\n          console.error('Error accessing webcam: ', err);\r\n        });\r\n    };\r\n\r\n    const handleVideoOnPlay = () => {\r\n      setInterval(async () => {\r\n        if (videoRef.current) {\r\n          const detections = await faceapi.detectAllFaces(\r\n            videoRef.current,\r\n            new faceapi.TinyFaceDetectorOptions()\r\n          ).withFaceExpressions();\r\n          if (detections.length > 0) {\r\n            const emotions = detections[0].expressions;\r\n            const maxEmotion = Object.keys(emotions).reduce((a, b) => emotions[a] > emotions[b] ? a : b);\r\n            setEmotion(maxEmotion);\r\n            sendData(maxEmotion);\r\n          }\r\n        }\r\n      }, 1000);\r\n    };\r\n\r\n    const initialize = async () => {\r\n      await loadModels();\r\n      startVideo();\r\n      videoRef.current.addEventListener('play', handleVideoOnPlay);\r\n    };\r\n\r\n    initialize();\r\n\r\n    return () => {\r\n      if (videoRef.current) {\r\n        videoRef.current.removeEventListener('play', handleVideoOnPlay);\r\n        if (videoRef.current.srcObject) {\r\n          videoRef.current.srcObject.getTracks().forEach(track => track.stop());\r\n        }\r\n      }\r\n    };\r\n  }, [setEmotion]);\r\n\r\n  const sendData = (emotion) => {\r\n    if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {\r\n      socketRef.current.send(JSON.stringify({ emotion }));\r\n    }\r\n  };\r\n\r\n  useEffect(() => {\r\n    socketRef.current = new WebSocket('ws://localhost:8000/ws/pessimism_detection/');\r\n    socketRef.current.onopen = () => {\r\n      console.log('WebSocket connected');\r\n    };\r\n    socketRef.current.onclose = () => {\r\n      console.log('WebSocket disconnected');\r\n    };\r\n\r\n    return () => {\r\n      if (socketRef.current) {\r\n        socketRef.current.close();\r\n      }\r\n    };\r\n  }, []);\r\n\r\n  return (\r\n    <div>\r\n      <video ref={videoRef} autoPlay muted style={{ display: 'none' }} />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default EmotionDetection;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,QAAQ,OAAO;AAChD,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,gBAAgB,GAAGC,IAAA,IAAoB;EAAAC,EAAA;EAAA,IAAnB;IAAEC;EAAW,CAAC,GAAAF,IAAA;EACtC,MAAMG,QAAQ,GAAGT,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMU,SAAS,GAAGV,MAAM,CAAC,IAAI,CAAC;EAE9BC,SAAS,CAAC,MAAM;IACd,MAAMU,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMC,SAAS,GAAG,SAAS;MAC3B,MAAMV,OAAO,CAACW,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAACH,SAAS,CAAC;MAC1D,MAAMV,OAAO,CAACW,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAACH,SAAS,CAAC;IAC7D,CAAC;IAED,MAAMK,UAAU,GAAGA,CAAA,KAAM;MACvBC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE,CAAC;MAAE,CAAC,CAAC,CAC/CC,IAAI,CAAEC,MAAM,IAAK;QAChBd,QAAQ,CAACe,OAAO,CAACC,SAAS,GAAGF,MAAM;MACrC,CAAC,CAAC,CACDG,KAAK,CAAEC,GAAG,IAAK;QACdC,OAAO,CAACC,KAAK,CAAC,0BAA0B,EAAEF,GAAG,CAAC;MAChD,CAAC,CAAC;IACN,CAAC;IAED,MAAMG,iBAAiB,GAAGA,CAAA,KAAM;MAC9BC,WAAW,CAAC,YAAY;QACtB,IAAItB,QAAQ,CAACe,OAAO,EAAE;UACpB,MAAMQ,UAAU,GAAG,MAAM9B,OAAO,CAAC+B,cAAc,CAC7CxB,QAAQ,CAACe,OAAO,EAChB,IAAItB,OAAO,CAACgC,uBAAuB,CAAC,CACtC,CAAC,CAACC,mBAAmB,CAAC,CAAC;UACvB,IAAIH,UAAU,CAACI,MAAM,GAAG,CAAC,EAAE;YACzB,MAAMC,QAAQ,GAAGL,UAAU,CAAC,CAAC,CAAC,CAACM,WAAW;YAC1C,MAAMC,UAAU,GAAGC,MAAM,CAACC,IAAI,CAACJ,QAAQ,CAAC,CAACK,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKP,QAAQ,CAACM,CAAC,CAAC,GAAGN,QAAQ,CAACO,CAAC,CAAC,GAAGD,CAAC,GAAGC,CAAC,CAAC;YAC5FpC,UAAU,CAAC+B,UAAU,CAAC;YACtBM,QAAQ,CAACN,UAAU,CAAC;UACtB;QACF;MACF,CAAC,EAAE,IAAI,CAAC;IACV,CAAC;IAED,MAAMO,UAAU,GAAG,MAAAA,CAAA,KAAY;MAC7B,MAAMnC,UAAU,CAAC,CAAC;MAClBM,UAAU,CAAC,CAAC;MACZR,QAAQ,CAACe,OAAO,CAACuB,gBAAgB,CAAC,MAAM,EAAEjB,iBAAiB,CAAC;IAC9D,CAAC;IAEDgB,UAAU,CAAC,CAAC;IAEZ,OAAO,MAAM;MACX,IAAIrC,QAAQ,CAACe,OAAO,EAAE;QACpBf,QAAQ,CAACe,OAAO,CAACwB,mBAAmB,CAAC,MAAM,EAAElB,iBAAiB,CAAC;QAC/D,IAAIrB,QAAQ,CAACe,OAAO,CAACC,SAAS,EAAE;UAC9BhB,QAAQ,CAACe,OAAO,CAACC,SAAS,CAACwB,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QACvE;MACF;IACF,CAAC;EACH,CAAC,EAAE,CAAC5C,UAAU,CAAC,CAAC;EAEhB,MAAMqC,QAAQ,GAAIQ,OAAO,IAAK;IAC5B,IAAI3C,SAAS,CAACc,OAAO,IAAId,SAAS,CAACc,OAAO,CAAC8B,UAAU,KAAKC,SAAS,CAACC,IAAI,EAAE;MACxE9C,SAAS,CAACc,OAAO,CAACiC,IAAI,CAACC,IAAI,CAACC,SAAS,CAAC;QAAEN;MAAQ,CAAC,CAAC,CAAC;IACrD;EACF,CAAC;EAEDpD,SAAS,CAAC,MAAM;IACdS,SAAS,CAACc,OAAO,GAAG,IAAI+B,SAAS,CAAC,6CAA6C,CAAC;IAChF7C,SAAS,CAACc,OAAO,CAACoC,MAAM,GAAG,MAAM;MAC/BhC,OAAO,CAACiC,GAAG,CAAC,qBAAqB,CAAC;IACpC,CAAC;IACDnD,SAAS,CAACc,OAAO,CAACsC,OAAO,GAAG,MAAM;MAChClC,OAAO,CAACiC,GAAG,CAAC,wBAAwB,CAAC;IACvC,CAAC;IAED,OAAO,MAAM;MACX,IAAInD,SAAS,CAACc,OAAO,EAAE;QACrBd,SAAS,CAACc,OAAO,CAACuC,KAAK,CAAC,CAAC;MAC3B;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN,oBACE3D,OAAA;IAAA4D,QAAA,eACE5D,OAAA;MAAO6D,GAAG,EAAExD,QAAS;MAACyD,QAAQ;MAACC,KAAK;MAACC,KAAK,EAAE;QAAEC,OAAO,EAAE;MAAO;IAAE;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAChE,CAAC;AAEV,CAAC;AAAClE,EAAA,CAnFIF,gBAAgB;AAAAqE,EAAA,GAAhBrE,gBAAgB;AAqFtB,eAAeA,gBAAgB;AAAC,IAAAqE,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}