{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\janry\\\\Music\\\\VisualQuery\\\\frontend\\\\src\\\\component\\\\HeadPoseAndEmotionDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useRef, useEffect, useState } from 'eact';\nimport * as mp from '@mediapipe/face_mesh';\nimport * as cam from '@mediapipe/camera_utils';\nimport * as faceapi from 'face-api.js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst HeadPoseAndEmotionDetection = _ref => {\n  _s();\n  let {\n    setHeadPose,\n    setEmotion\n  } = _ref;\n  const videoRef = useRef(null);\n  const [isModelsLoaded, setIsModelsLoaded] = useState(false);\n  const faceMeshRef = useRef(null);\n  const cameraRef = useRef(null);\n  useEffect(() => {\n    const loadFaceApiModels = async () => {\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\n      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\n      setIsModelsLoaded(true);\n    };\n    const startVideoAndDetection = async () => {\n      if (!videoRef.current) return;\n      const faceMesh = new mp.FaceMesh({\n        locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`\n      });\n      faceMeshRef.current = faceMesh;\n      faceMesh.setOptions({\n        maxNumFaces: 1,\n        refineLandmarks: true,\n        minDetectionConfidence: 0.5,\n        minTrackingConfidence: 0.5\n      });\n      faceMesh.onResults(onResults);\n      let camera;\n      camera = new cam.Camera(videoRef.current, {\n        onFrame: async () => {\n          await faceMesh.send({\n            image: videoRef.current\n          });\n          if (isModelsLoaded) {\n            detectEmotion();\n          }\n        },\n        width: 640,\n        height: 480\n      });\n      cameraRef.current = camera;\n      camera.start();\n    };\n    function onResults(results) {\n      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {\n        const landmarks = results.multiFaceLandmarks[0];\n        const noseTip = landmarks[1];\n        const leftCheek = landmarks[33];\n        const rightCheek = landmarks[263];\n        const dx = rightCheek.x - leftCheek.x;\n        const dy = rightCheek.y - leftCheek.y;\n        const angleY = Math.atan2(dy, dx) * (180 / Math.PI);\n        const noseBottom = landmarks[2];\n        const chin = landmarks[152];\n        const dz = chin.y - noseBottom.y;\n        const angleX = Math.atan2(dz, dx) * (180 / Math.PI);\n        let pose = 'forward';\n        if (angleY < -10) {\n          pose = 'left';\n        } else if (angleX > 17) {\n          pose = 'up';\n        } else if (angleX < -1) {\n          pose = 'down';\n        }\n        setHeadPose(pose);\n      }\n    }\n    const detectEmotion = async () => {\n      if (videoRef.current) {\n        const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\n        if (detections.length > 0) {\n          const emotions = detections[0].expressions;\n          const maxValue = Math.max(...Object.values(emotions));\n          const emotion = Object.keys(emotions).find(key => emotions[key] === maxValue);\n          setEmotion(emotion);\n        }\n      }\n    };\n    loadFaceApiModels().then(startVideoAndDetection);\n    return () => {\n      if (faceMeshRef.current) {\n        faceMeshRef.current.close();\n        faceMeshRef.current.removeEventListener('results', onResults);\n      }\n      if (cameraRef.current) {\n        cameraRef.current.stop();\n      }\n    };\n  }, [setHeadPose, setEmotion]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      autoPlay: true,\n      muted: true,\n      width: \"640\",\n      height: \"480\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 112,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 111,\n    columnNumber: 5\n  }, this);\n};\n_s(HeadPoseAndEmotionDetection, \"B3CWGcS12j3YmQJKGnLik09tz+M=\");\n_c = HeadPoseAndEmotionDetection;\nexport default HeadPoseAndEmotionDetection;\nvar _c;\n$RefreshReg$(_c, \"HeadPoseAndEmotionDetection\");","map":{"version":3,"names":["React","useRef","useEffect","useState","mp","cam","faceapi","jsxDEV","_jsxDEV","HeadPoseAndEmotionDetection","_ref","_s","setHeadPose","setEmotion","videoRef","isModelsLoaded","setIsModelsLoaded","faceMeshRef","cameraRef","loadFaceApiModels","nets","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","startVideoAndDetection","current","faceMesh","FaceMesh","locateFile","file","setOptions","maxNumFaces","refineLandmarks","minDetectionConfidence","minTrackingConfidence","onResults","camera","Camera","onFrame","send","image","detectEmotion","width","height","start","results","multiFaceLandmarks","length","landmarks","noseTip","leftCheek","rightCheek","dx","x","dy","y","angleY","Math","atan2","PI","noseBottom","chin","dz","angleX","pose","detections","detectAllFaces","TinyFaceDetectorOptions","withFaceLandmarks","withFaceExpressions","emotions","expressions","maxValue","max","Object","values","emotion","keys","find","key","then","close","removeEventListener","stop","children","ref","autoPlay","muted","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/janry/Music/VisualQuery/frontend/src/component/HeadPoseAndEmotionDetection.js"],"sourcesContent":["import React, { useRef, useEffect, useState } from 'eact';\r\nimport * as mp from '@mediapipe/face_mesh';\r\nimport * as cam from '@mediapipe/camera_utils';\r\nimport * as faceapi from 'face-api.js';\r\n\r\nconst HeadPoseAndEmotionDetection = ({ setHeadPose, setEmotion }) => {\r\n  const videoRef = useRef(null);\r\n  const [isModelsLoaded, setIsModelsLoaded] = useState(false);\r\n  const faceMeshRef = useRef(null);\r\n  const cameraRef = useRef(null);\r\n\r\n  useEffect(() => {\r\n    const loadFaceApiModels = async () => {\r\n      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\r\n      await faceapi.nets.faceLandmark68Net.loadFromUri('/models');\r\n      await faceapi.nets.faceRecognitionNet.loadFromUri('/models');\r\n      await faceapi.nets.faceExpressionNet.loadFromUri('/models');\r\n      setIsModelsLoaded(true);\r\n    };\r\n\r\n    const startVideoAndDetection = async () => {\r\n      if (!videoRef.current) return;\r\n\r\n      const faceMesh = new mp.FaceMesh({\r\n        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,\r\n      });\r\n\r\n      faceMeshRef.current = faceMesh;\r\n\r\n      faceMesh.setOptions({\r\n        maxNumFaces: 1,\r\n        refineLandmarks: true,\r\n        minDetectionConfidence: 0.5,\r\n        minTrackingConfidence: 0.5,\r\n      });\r\n\r\n      faceMesh.onResults(onResults);\r\n\r\n      let camera;\r\n      camera = new cam.Camera(videoRef.current, {\r\n        onFrame: async () => {\r\n          await faceMesh.send({ image: videoRef.current });\r\n          if (isModelsLoaded) {\r\n            detectEmotion();\r\n          }\r\n        },\r\n        width: 640,\r\n        height: 480,\r\n      });\r\n      cameraRef.current = camera;\r\n      camera.start();\r\n    };\r\n\r\n    function onResults(results) {\r\n      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {\r\n        const landmarks = results.multiFaceLandmarks[0];\r\n\r\n        const noseTip = landmarks[1];\r\n        const leftCheek = landmarks[33];\r\n        const rightCheek = landmarks[263];\r\n\r\n        const dx = rightCheek.x - leftCheek.x;\r\n        const dy = rightCheek.y - leftCheek.y;\r\n        const angleY = Math.atan2(dy, dx) * (180 / Math.PI);\r\n\r\n        const noseBottom = landmarks[2];\r\n        const chin = landmarks[152];\r\n\r\n        const dz = chin.y - noseBottom.y;\r\n        const angleX = Math.atan2(dz, dx) * (180 / Math.PI);\r\n\r\n        let pose = 'forward';\r\n        if (angleY < -10) {\r\n          pose = 'left';\r\n        } else if (angleX > 17) {\r\n          pose = 'up';\r\n        } else if (angleX < -1) {\r\n          pose = 'down';\r\n        }\r\n\r\n        setHeadPose(pose);\r\n      }\r\n    }\r\n\r\n    const detectEmotion = async () => {\r\n      if (videoRef.current) {\r\n        const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();\r\n        if (detections.length > 0) {\r\n          const emotions = detections[0].expressions;\r\n          const maxValue = Math.max(...Object.values(emotions));\r\n          const emotion = Object.keys(emotions).find(key => emotions[key] === maxValue);\r\n          setEmotion(emotion);\r\n        }\r\n      }\r\n    };\r\n\r\n    loadFaceApiModels().then(startVideoAndDetection);\r\n\r\n    return () => {\r\n      if (faceMeshRef.current) {\r\n        faceMeshRef.current.close();\r\n        faceMeshRef.current.removeEventListener('results', onResults);\r\n      }\r\n      if (cameraRef.current) {\r\n        cameraRef.current.stop();\r\n      }\r\n    };\r\n  }, [setHeadPose, setEmotion]);\r\n\r\n  return (\r\n    <div>\r\n      <video ref={videoRef} autoPlay muted width=\"640\" height=\"480\" />\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default HeadPoseAndEmotionDetection;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,MAAM,EAAEC,SAAS,EAAEC,QAAQ,QAAQ,MAAM;AACzD,OAAO,KAAKC,EAAE,MAAM,sBAAsB;AAC1C,OAAO,KAAKC,GAAG,MAAM,yBAAyB;AAC9C,OAAO,KAAKC,OAAO,MAAM,aAAa;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,2BAA2B,GAAGC,IAAA,IAAiC;EAAAC,EAAA;EAAA,IAAhC;IAAEC,WAAW;IAAEC;EAAW,CAAC,GAAAH,IAAA;EAC9D,MAAMI,QAAQ,GAAGb,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAM,CAACc,cAAc,EAAEC,iBAAiB,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC;EAC3D,MAAMc,WAAW,GAAGhB,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMiB,SAAS,GAAGjB,MAAM,CAAC,IAAI,CAAC;EAE9BC,SAAS,CAAC,MAAM;IACd,MAAMiB,iBAAiB,GAAG,MAAAA,CAAA,KAAY;MACpC,MAAMb,OAAO,CAACc,IAAI,CAACC,gBAAgB,CAACC,WAAW,CAAC,SAAS,CAAC;MAC1D,MAAMhB,OAAO,CAACc,IAAI,CAACG,iBAAiB,CAACD,WAAW,CAAC,SAAS,CAAC;MAC3D,MAAMhB,OAAO,CAACc,IAAI,CAACI,kBAAkB,CAACF,WAAW,CAAC,SAAS,CAAC;MAC5D,MAAMhB,OAAO,CAACc,IAAI,CAACK,iBAAiB,CAACH,WAAW,CAAC,SAAS,CAAC;MAC3DN,iBAAiB,CAAC,IAAI,CAAC;IACzB,CAAC;IAED,MAAMU,sBAAsB,GAAG,MAAAA,CAAA,KAAY;MACzC,IAAI,CAACZ,QAAQ,CAACa,OAAO,EAAE;MAEvB,MAAMC,QAAQ,GAAG,IAAIxB,EAAE,CAACyB,QAAQ,CAAC;QAC/BC,UAAU,EAAGC,IAAI,IAAM,qDAAoDA,IAAK;MAClF,CAAC,CAAC;MAEFd,WAAW,CAACU,OAAO,GAAGC,QAAQ;MAE9BA,QAAQ,CAACI,UAAU,CAAC;QAClBC,WAAW,EAAE,CAAC;QACdC,eAAe,EAAE,IAAI;QACrBC,sBAAsB,EAAE,GAAG;QAC3BC,qBAAqB,EAAE;MACzB,CAAC,CAAC;MAEFR,QAAQ,CAACS,SAAS,CAACA,SAAS,CAAC;MAE7B,IAAIC,MAAM;MACVA,MAAM,GAAG,IAAIjC,GAAG,CAACkC,MAAM,CAACzB,QAAQ,CAACa,OAAO,EAAE;QACxCa,OAAO,EAAE,MAAAA,CAAA,KAAY;UACnB,MAAMZ,QAAQ,CAACa,IAAI,CAAC;YAAEC,KAAK,EAAE5B,QAAQ,CAACa;UAAQ,CAAC,CAAC;UAChD,IAAIZ,cAAc,EAAE;YAClB4B,aAAa,CAAC,CAAC;UACjB;QACF,CAAC;QACDC,KAAK,EAAE,GAAG;QACVC,MAAM,EAAE;MACV,CAAC,CAAC;MACF3B,SAAS,CAACS,OAAO,GAAGW,MAAM;MAC1BA,MAAM,CAACQ,KAAK,CAAC,CAAC;IAChB,CAAC;IAED,SAAST,SAASA,CAACU,OAAO,EAAE;MAC1B,IAAIA,OAAO,CAACC,kBAAkB,IAAID,OAAO,CAACC,kBAAkB,CAACC,MAAM,GAAG,CAAC,EAAE;QACvE,MAAMC,SAAS,GAAGH,OAAO,CAACC,kBAAkB,CAAC,CAAC,CAAC;QAE/C,MAAMG,OAAO,GAAGD,SAAS,CAAC,CAAC,CAAC;QAC5B,MAAME,SAAS,GAAGF,SAAS,CAAC,EAAE,CAAC;QAC/B,MAAMG,UAAU,GAAGH,SAAS,CAAC,GAAG,CAAC;QAEjC,MAAMI,EAAE,GAAGD,UAAU,CAACE,CAAC,GAAGH,SAAS,CAACG,CAAC;QACrC,MAAMC,EAAE,GAAGH,UAAU,CAACI,CAAC,GAAGL,SAAS,CAACK,CAAC;QACrC,MAAMC,MAAM,GAAGC,IAAI,CAACC,KAAK,CAACJ,EAAE,EAAEF,EAAE,CAAC,IAAI,GAAG,GAAGK,IAAI,CAACE,EAAE,CAAC;QAEnD,MAAMC,UAAU,GAAGZ,SAAS,CAAC,CAAC,CAAC;QAC/B,MAAMa,IAAI,GAAGb,SAAS,CAAC,GAAG,CAAC;QAE3B,MAAMc,EAAE,GAAGD,IAAI,CAACN,CAAC,GAAGK,UAAU,CAACL,CAAC;QAChC,MAAMQ,MAAM,GAAGN,IAAI,CAACC,KAAK,CAACI,EAAE,EAAEV,EAAE,CAAC,IAAI,GAAG,GAAGK,IAAI,CAACE,EAAE,CAAC;QAEnD,IAAIK,IAAI,GAAG,SAAS;QACpB,IAAIR,MAAM,GAAG,CAAC,EAAE,EAAE;UAChBQ,IAAI,GAAG,MAAM;QACf,CAAC,MAAM,IAAID,MAAM,GAAG,EAAE,EAAE;UACtBC,IAAI,GAAG,IAAI;QACb,CAAC,MAAM,IAAID,MAAM,GAAG,CAAC,CAAC,EAAE;UACtBC,IAAI,GAAG,MAAM;QACf;QAEAtD,WAAW,CAACsD,IAAI,CAAC;MACnB;IACF;IAEA,MAAMvB,aAAa,GAAG,MAAAA,CAAA,KAAY;MAChC,IAAI7B,QAAQ,CAACa,OAAO,EAAE;QACpB,MAAMwC,UAAU,GAAG,MAAM7D,OAAO,CAAC8D,cAAc,CAACtD,QAAQ,CAACa,OAAO,EAAE,IAAIrB,OAAO,CAAC+D,uBAAuB,CAAC,CAAC,CAAC,CAACC,iBAAiB,CAAC,CAAC,CAACC,mBAAmB,CAAC,CAAC;QAClJ,IAAIJ,UAAU,CAAClB,MAAM,GAAG,CAAC,EAAE;UACzB,MAAMuB,QAAQ,GAAGL,UAAU,CAAC,CAAC,CAAC,CAACM,WAAW;UAC1C,MAAMC,QAAQ,GAAGf,IAAI,CAACgB,GAAG,CAAC,GAAGC,MAAM,CAACC,MAAM,CAACL,QAAQ,CAAC,CAAC;UACrD,MAAMM,OAAO,GAAGF,MAAM,CAACG,IAAI,CAACP,QAAQ,CAAC,CAACQ,IAAI,CAACC,GAAG,IAAIT,QAAQ,CAACS,GAAG,CAAC,KAAKP,QAAQ,CAAC;UAC7E7D,UAAU,CAACiE,OAAO,CAAC;QACrB;MACF;IACF,CAAC;IAED3D,iBAAiB,CAAC,CAAC,CAAC+D,IAAI,CAACxD,sBAAsB,CAAC;IAEhD,OAAO,MAAM;MACX,IAAIT,WAAW,CAACU,OAAO,EAAE;QACvBV,WAAW,CAACU,OAAO,CAACwD,KAAK,CAAC,CAAC;QAC3BlE,WAAW,CAACU,OAAO,CAACyD,mBAAmB,CAAC,SAAS,EAAE/C,SAAS,CAAC;MAC/D;MACA,IAAInB,SAAS,CAACS,OAAO,EAAE;QACrBT,SAAS,CAACS,OAAO,CAAC0D,IAAI,CAAC,CAAC;MAC1B;IACF,CAAC;EACH,CAAC,EAAE,CAACzE,WAAW,EAAEC,UAAU,CAAC,CAAC;EAE7B,oBACEL,OAAA;IAAA8E,QAAA,eACE9E,OAAA;MAAO+E,GAAG,EAAEzE,QAAS;MAAC0E,QAAQ;MAACC,KAAK;MAAC7C,KAAK,EAAC,KAAK;MAACC,MAAM,EAAC;IAAK;MAAA6C,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAC7D,CAAC;AAEV,CAAC;AAAClF,EAAA,CA7GIF,2BAA2B;AAAAqF,EAAA,GAA3BrF,2BAA2B;AA+GjC,eAAeA,2BAA2B;AAAC,IAAAqF,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}